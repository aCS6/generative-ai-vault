{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82732ebb-9724-49d5-93ae-3e10b02fa13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5181f2-d2f7-4b3e-81de-48ca142146e9",
   "metadata": {},
   "source": [
    "## Create LLM object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e63ce45a-632d-492f-96df-93a65b5d53e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x7cafd9f0d1e0> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7cafd9f0eb00> root_client=<openai.OpenAI object at 0x7cafec348b50> root_async_client=<openai.AsyncOpenAI object at 0x7cafd9f0d210> model_name='gpt-4o' openai_api_key=SecretStr('**********') openai_proxy=''\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd87e04-c348-461c-99af-ac6b26dc77b8",
   "metadata": {},
   "source": [
    "## Invoke LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7868154e-c0fb-4ee4-b989-d48401286440",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67808ba6-b5a5-4970-b2d0-27c571c903a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Generative AI refers to a class of artificial intelligence algorithms that can create new content, such as text, images, audio, and even video, by learning patterns from existing data. These algorithms are capable of producing outputs that are not merely reproductions of the input data but are instead new, original creations that are statistically similar to the training data.\\n\\nSome of the most well-known types of generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs)**: These consist of two neural networks, a generator and a discriminator, that are trained together. The generator creates new data instances, while the discriminator evaluates them. Over time, the generator becomes skilled at producing realistic data that can fool the discriminator.\\n\\n2. **Variational Autoencoders (VAEs)**: These are a type of autoencoder that learns to encode input data into a latent space and then decode it back into new data. VAEs can generate new data by sampling from the latent space.\\n\\n3. **Transformers**: Models like GPT (Generative Pre-trained Transformer) are based on transformer architecture. They can generate human-like text and have been used for tasks like language translation, summarization, and text completion.\\n\\n4. **Diffusion Models**: These models iteratively refine noisy data to generate high-quality samples. They have recently gained attention for their performance in generating images.\\n\\nApplications of generative AI are vast and include:\\n\\n- **Text Generation**: Writing articles, stories, or even code.\\n- **Image Generation**: Creating realistic images or art, enhancing photos.\\n- **Music Generation**: Composing new pieces of music.\\n- **Video Generation**: Producing new video content or enhancing existing footage.\\n- **Data Augmentation**: Generating synthetic data for training other AI models.\\n\\nGenerative AI is a rapidly evolving field and holds promise for numerous innovative applications, while also raising important ethical considerations around the originality and authenticity of generated content.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 392, 'prompt_tokens': 13, 'total_tokens': 405}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c9aa9c0491', 'finish_reason': 'stop', 'logprobs': None}, id='run-6a61019d-6d5f-4340-90d6-791d9f6afd0a-0', usage_metadata={'input_tokens': 13, 'output_tokens': 392, 'total_tokens': 405})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867274e4-1dd6-4e36-b9de-21c4d740c56c",
   "metadata": {},
   "source": [
    "## Chatprompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7de0cec-f09b-4265-853c-218de2e55d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are an expert AI Engineer. Provide me answers based on the questions')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9adb0a4-c8f8-4aec-8cd4-c250b3808642",
   "metadata": {},
   "source": [
    "## Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12732a48-da2d-40a4-8c25-463e8a7b90f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is a tool designed to enhance the development, testing, and monitoring of applications built using large language models (LLMs) and chains. It offers several features to streamline and optimize the implementation of LLM-based applications:\\n\\n1. **Tracer Integration**: Langsmith can be integrated as a tracer, which helps in tracking and debugging the execution of language models and chains. This is particularly useful for diagnosing issues and understanding the behavior of the models in real-time.\\n\\n2. **Development and Testing**: The platform provides functionalities to facilitate the development and testing processes. This includes tools to simulate different scenarios, test various configurations, and ensure robustness and reliability of the application.\\n\\n3. **Monitoring**: Once the application is deployed, Langsmith offers monitoring capabilities to keep track of performance metrics, usage patterns, and potential anomalies. This helps in maintaining the health of the application and making data-driven improvements.\\n\\n4. **Seamless Integration**: Langsmith is designed to work smoothly with existing LLM frameworks and chains, making it easier for developers to adopt without significant changes to their current workflows.\\n\\nOverall, Langsmith aims to provide a comprehensive suite of tools that support the entire lifecycle of LLM-based application development, from initial coding to deployment and ongoing maintenance.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 252, 'prompt_tokens': 33, 'total_tokens': 285}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27', 'finish_reason': 'stop', 'logprobs': None} id='run-82f8c66c-6e78-49c3-9e2f-ab873c38f615-0' usage_metadata={'input_tokens': 33, 'output_tokens': 252, 'total_tokens': 285}\n"
     ]
    }
   ],
   "source": [
    "#chain\n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2cafc7-c578-4290-8ef5-94aef8faec96",
   "metadata": {},
   "source": [
    "## Output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2904ca19-aa76-475a-8a51-b84a431bc358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! As of my last update in October 2023, LangSmith appears to be a product or tool related to the LangChain ecosystem. LangChain is a framework designed for developing applications powered by large language models (LLMs). Here's a detailed overview of LangSmith based on the available information:\n",
      "\n",
      "### What is LangSmith?\n",
      "\n",
      "LangSmith is a tool that provides robust monitoring and debugging capabilities for applications built using LangChain. It aims to enhance the development process by offering features that allow developers to track, analyze, and optimize their applications.\n",
      "\n",
      "### Key Features of LangSmith\n",
      "\n",
      "1. **Instrumentation for Tracing**:\n",
      "   - LangSmith can instrument LangChain code to produce detailed traces of application runs.\n",
      "   - These traces help developers understand the flow of execution and identify potential issues.\n",
      "\n",
      "2. **Execution Tracing**:\n",
      "   - Traces include information about the sequence of actions, input/output data, and the performance of each step.\n",
      "   - This is crucial for debugging and optimizing complex workflows that involve multiple interactions with language models.\n",
      "\n",
      "3. **Error Handling and Debugging**:\n",
      "   - LangSmith helps in pinpointing the exact location and cause of errors within the application.\n",
      "   - Developers can use these insights to fix bugs more efficiently.\n",
      "\n",
      "4. **Performance Monitoring**:\n",
      "   - By analyzing traces, developers can identify bottlenecks and optimize the performance of their applications.\n",
      "   - LangSmith provides metrics and visualizations to help understand the performance characteristics.\n",
      "\n",
      "5. **Integration with LangChain**:\n",
      "   - LangSmith is designed to work seamlessly with LangChain, leveraging its components and extending their capabilities.\n",
      "   - It supports various LangChain features such as chains, agents, and callbacks.\n",
      "\n",
      "6. **User Interface**:\n",
      "   - LangSmith offers a user-friendly interface for visualizing traces and metrics.\n",
      "   - This makes it easier for developers to interact with and understand the data generated by their applications.\n",
      "\n",
      "### Use Cases\n",
      "\n",
      "- **Application Development**: LangSmith can be used during the development phase to ensure that applications are functioning as intended.\n",
      "- **Debugging**: When issues arise, developers can use LangSmith to trace the problem back to its source.\n",
      "- **Optimization**: By monitoring performance, developers can make data-driven decisions to optimize their applications.\n",
      "\n",
      "### How to Use LangSmith\n",
      "\n",
      "To use LangSmith, developers typically need to integrate it with their existing LangChain codebase. This involves adding instrumentation code and configuring LangSmith to collect and display traces. The exact steps can vary based on the specific requirements and setup of the application.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "LangSmith is a powerful tool for developers working with LangChain, providing essential capabilities for tracing, debugging, and optimizing applications powered by large language models. By offering detailed insights into the execution of LangChain applications, LangSmith helps developers build more reliable, efficient, and performant applications.\n",
      "\n",
      "For the most up-to-date information and detailed documentation, you would likely want to visit the official LangChain website or the LangSmith documentation page.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b543177-89ba-4699-a67a-74544905ffaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
